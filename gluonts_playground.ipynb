{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b3f08-642f-4b99-9b2e-f590ab853f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f0cd5-04b6-46f5-a8b6-8fcf415da74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gluonts.dataset.repository import get_dataset, dataset_names\n",
    "from gluonts.dataset.util import to_pandas\n",
    "print(f\"Available datasets: {dataset_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4341da-136d-4a16-b18e-7512f5b64634",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names\n",
    "dataset = get_dataset(\"m4_hourly\")\n",
    "dataset.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c0c3b-1c8e-4067-90d3-b09f3564958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_iterable = iter(dataset.train)\n",
    "#entry = next(iter(dataset.train))\n",
    "entry = next(entry_iterable)\n",
    "train_series = to_pandas(entry)\n",
    "train_series.plot(c='b',marker='x')\n",
    "#plt.grid(which=\"both\")\n",
    "#plt.legend([\"train series\"], loc=\"upper left\")\n",
    "entry_2 = next(entry_iterable)\n",
    "#entry_2 = next(iter(dataset.train))\n",
    "print(f\"type(entry): {type(entry)}\")\n",
    "train_series_2 = to_pandas(entry_2)\n",
    "train_series_2.plot(c='r',marker='o')\n",
    "plt.grid(which=\"both\")\n",
    "plt.legend([\"train series_2\"], loc=\"upper left\")\n",
    "\n",
    "plt.show()\n",
    "train_series==train_series_2\n",
    "count = 0\n",
    "plt.figure()\n",
    "for entry_idx, entry_data in enumerate(dataset.train):\n",
    "    count +=1\n",
    "    cur_entry_data = to_pandas(entry_data)\n",
    "    if entry_idx > 1:# and entry_idx <= 3:\n",
    "        #print(f\"{to_pandas(entry_data)}\")\n",
    "        \n",
    "        print(f\"{np.all(to_pandas(entry_data)==to_pandas(entry_data_prev))}\")\n",
    "        \n",
    "    cur_entry_data.plot(marker='o',label=entry_idx)\n",
    "    entry_data_prev = entry_data\n",
    "    if entry_idx == 40:\n",
    "        break\n",
    "plt.grid(which=\"both\")\n",
    "plt.legend( loc=\"upper left\")\n",
    "\n",
    "print(f\"Counter: {entry_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe9031",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92920c40-ee3e-44d3-92ce-4aab2fb80124",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = next(iter(dataset.test))\n",
    "test_series = to_pandas(entry)\n",
    "test_series.plot()\n",
    "plt.axvline(train_series.index[-1], color=\"r\")  # end of train dataset\n",
    "plt.grid(which=\"both\")\n",
    "plt.legend([\"test series\", \"end of train series\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4453974",
   "metadata": {},
   "source": [
    "# NB: Why it seems that only first item from dataset.[train|test] is used in this analysis prediction. Other items have totally different means and variances. That is, is estimator with call predictor = estimator.train(dataset.train) really getting only the above series? No, all series are passed, but only 0th is analyzed in the tutorial. You can access the next dataseries with indexing \"1\", the third \"2\", etc. That is, all data series are getting predicted with above call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b7800-c3c7-4f5d-82a4-8a885b6d03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Length of forecasting window in test dataset: {len(test_series) - len(train_series)}\"\n",
    ")\n",
    "print(f\"Recommended prediction horizon: {dataset.metadata.prediction_length}\")\n",
    "print(f\"Frequency of the time series: {dataset.metadata.freq}\")\n",
    "print(\n",
    "    f\"Length of test dataset: {len(test_series)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Length of train dataset: {len(train_series)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765bbe84-651f-425d-929f-dcadbc14d450",
   "metadata": {},
   "source": [
    "# Custom data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc9dad-1711-4f37-95d2-1f36f0dc92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10  # number of time series\n",
    "T = 100  # number of timesteps\n",
    "prediction_length = 24\n",
    "freq = \"1H\"\n",
    "custom_dataset = np.random.normal(size=(N, T))\n",
    "start = pd.Period(\"01-01-2019\", freq=freq)  # can be different for each time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344903c3-3a92-4931-ab6b-0f636df1281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d6fd3-105f-49e7-9a89-96c7ef0d882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.common import ListDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ea3e5-c2bc-4603-81fd-903e107292bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset: cut the last window of length \"prediction_length\", add \"target\" and \"start\" fields\n",
    "train_ds = ListDataset(\n",
    "    [{\"target\": x, \"start\": start} for x in custom_dataset[:, :-prediction_length]],\n",
    "    freq=freq,\n",
    ")\n",
    "# test dataset: use the whole dataset, add \"target\" and \"start\" fields\n",
    "test_ds = ListDataset(\n",
    "    [{\"target\": x, \"start\": start} for x in custom_dataset], freq=freq\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639aaf32-7751-40ff-b18b-2c6c7fb129d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset[:, :-prediction_length].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b0d73-e49d-4f63-a151-b356f9fd43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset[:, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee33cbb-b5f5-4aaa-8520-9ff377c128c4",
   "metadata": {},
   "source": [
    "# Training an existing model (Estimator)\n",
    "GluonTS comes with a number of pre-built models. All the user needs to do is configure some hyperparameters. The existing models focus on (but are not limited to) probabilistic forecasting. Probabilistic forecasts are predictions in the form of a probability distribution, rather than simply a single point estimate.\n",
    "\n",
    "We will begin with GluonTS’s pre-built feedforward neural network estimator, a simple but powerful forecasting model. We will use this model to demonstrate the process of training a model, producing forecasts, and evaluating the results.\n",
    "\n",
    "GluonTS’s built-in feedforward neural network (SimpleFeedForwardEstimator) accepts an input window of length context_length and predicts the distribution of the values of the subsequent prediction_length values. In GluonTS parlance, the feedforward neural network model is an example of an Estimator. In GluonTS, Estimator objects represent a forecasting model as well as details such as its coefficients, weights, etc.\n",
    "\n",
    "In general, each estimator (pre-built or custom) is configured by a number of hyperparameters that can be either common (but not binding) among all estimators (e.g., the prediction_length) or specific for the particular estimator (e.g., number of layers for a neural network or the stride in a CNN).\n",
    "\n",
    "Finally, each estimator is configured by a Trainer, which defines how the model will be trained i.e., the number of epochs, the learning rate, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090032a-5341-4909-af4e-29268eb2006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.mx import SimpleFeedForwardEstimator, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327086ec-00f6-4ab2-b1c9-53ab6c98e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SimpleFeedForwardEstimator(\n",
    "    num_hidden_dimensions=[10],\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    context_length=100,\n",
    "    trainer=Trainer(ctx=\"cpu\", epochs=5, learning_rate=1e-3, num_batches_per_epoch=100),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a4db0-4a86-4f8c-bbff-87167c2bacf2",
   "metadata": {},
   "source": [
    "After specifying our estimator with all the necessary hyperparameters we can train it using our training dataset dataset.train by invoking the train method of the estimator. The training algorithm returns a fitted model (or a Predictor in GluonTS parlance) that can be used to construct forecasts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b5a80-9df8-4319-ad60-39f41d74109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.train(dataset.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a632bcf-7b1b-47a7-b725-8415cf9fabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.metadata.prediction_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078bd65-7c54-47b3-bd26-f7b21d5397ac",
   "metadata": {},
   "source": [
    "# Visualize and evaluate forecasts\n",
    "With a predictor in hand, we can now predict the last window of the dataset.test and evaluate our model’s performance.\n",
    "\n",
    "GluonTS comes with the make_evaluation_predictions function that automates the process of prediction and model evaluation. Roughly, this function performs the following steps:\n",
    "\n",
    "- Removes the final window of length prediction_length of the dataset.test that we want to predict\n",
    "- The estimator uses the remaining data to predict (in the form of sample paths) the “future” window that was just removed\n",
    "- The module outputs the forecast sample paths and the dataset.test (as python generator objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c804c-0159-4b0c-b02c-c456b0fbe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.metadata.prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d05d6e-f5d3-486f-a151-1e98791e86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.evaluation import make_evaluation_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9f65a-8a38-4638-adf1-44e86c2dd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=dataset.test,  # test dataset\n",
    "    predictor=predictor,  # predictor\n",
    "    num_samples=100,  # number of sample paths we want for evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727c68a-9fab-4e16-b1d0-419872985b8f",
   "metadata": {},
   "source": [
    "First, we can convert these generators to lists to ease the subsequent computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e75528-aa19-4b15-a243-6deb6117af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = list(forecast_it)\n",
    "tss = list(ts_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede83a8-9304-4541-b9f9-a02761ab9a4d",
   "metadata": {},
   "source": [
    "We can examine the first element of these lists (that corresponds to the first time series of the dataset). Let’s start with the list containing the time series, i.e., tss. We expect the first entry of tss to contain the (target of the) first time series of dataset.test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f1b8b-ea8b-4a3d-b2d1-31bf89b450f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first entry of the time series list\n",
    "ts_entry = tss[0]\n",
    "# the second entry of the time series\n",
    "ts_entry = tss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b93e5f-de11-4e47-995b-9b63cc330f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 5 values of the time series (convert from pandas to numpy)\n",
    "np.array(ts_entry[:5]).reshape(\n",
    "    -1,\n",
    ")\n",
    "#np.array(ts_entry).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002e199-1803-4a0a-b11f-a7c049302d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900fa56-d8ca-4fce-9847-e6281cdbc9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first entry of dataset.test\n",
    "dataset_test_entry_iterable = (iter(dataset.test))\n",
    "dataset_test_entry = next(dataset_test_entry_iterable)\n",
    "# the second entry of dataset.test\n",
    "dataset_test_entry = next(dataset_test_entry_iterable)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43312c6-acb4-4e24-9c18-91adf4374daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 5 values\n",
    "dataset_test_entry[\"target\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4233e053-fece-4c91-a505-6a2f1a188017",
   "metadata": {},
   "source": [
    "The entries in the forecast list are a bit more complex. They are objects that contain all the sample paths in the form of numpy.ndarray with dimension (num_samples, prediction_length), the start date of the forecast, the frequency of the time series, etc. We can access all this information by simply invoking the corresponding attribute of the forecast object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c012a4-f2ef-4954-b4d6-4a0cb2593be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first entry of the forecast list\n",
    "forecast_entry = forecasts[0]\n",
    "# the second entry of the forecast list\n",
    "forecast_entry = forecasts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e46f3-9cac-45cc-9e1b-dd30875754a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of sample paths: {forecast_entry.num_samples}\")\n",
    "print(f\"Dimension of samples: {forecast_entry.samples.shape}\")\n",
    "print(f\"Start date of the forecast window: {forecast_entry.start_date}\")\n",
    "print(f\"Frequency of the time series: {forecast_entry.freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e80652-4c8f-4aab-8884-ed4ea0e4f51d",
   "metadata": {},
   "source": [
    "We can also do calculations to summarize the sample paths, such as computing the mean or a quantile for each of the 48 time steps in the forecast window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650cc39-5662-4b38-a010-363a4ca2fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean of the future window:\\n {forecast_entry.mean}\")\n",
    "print(f\"0.5-quantile (median) of the future window:\\n {forecast_entry.quantile(0.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc047d1c-6cd0-41f5-94a6-da6b2610444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_entry.mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b3b03-0b0e-4225-86d3-025b0da19fd9",
   "metadata": {},
   "source": [
    "Forecast objects have a plot method that can summarize the forecast paths as the mean, prediction intervals, etc. The prediction intervals are shaded in different colors as a “fan chart”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f81bb6-54fc-4a51-873a-dd6d9afb303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_entry[-150:].to_timestamp())\n",
    "forecast_entry.plot(show_label=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2c404-1b6b-49fe-9340-e399c644e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_entry[-150:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e54012-a2a5-4990-8eb0-2dfdc0b90c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_entry[-150:].to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bacb9d-dd13-43ce-8050-5eb67bfc1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_entry.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd8b1a-4b83-46cf-9bd1-dbc8afecb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_entry.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e6460-746d-4dd1-90ff-41f25fd76048",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_entry.samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520a581-fa01-418b-b590-043c3a5fb6d5",
   "metadata": {},
   "source": [
    "We can also evaluate the quality of our forecasts numerically. In GluonTS, the Evaluator class can compute aggregate performance metrics, as well as metrics per time series (which can be useful for analyzing performance across heterogeneous time series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b64150-818f-430f-bae4-7852259ca84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.evaluation import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba1355-1df0-4c08-8542-ac3a65d36634",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "agg_metrics, item_metrics = evaluator(tss, forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28b5b8-b6e3-4ed4-98e1-68d733490625",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tss) # number of different time series?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3fa62c-88a9-4258-9df5-03002d091fe1",
   "metadata": {},
   "source": [
    "The aggregate metrics, agg_metrics, aggregate both across time-steps and across time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949fa4e-7b47-4fd7-99ec-ed8f5812e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(agg_metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab92b6d-8005-45bb-86cb-989e6a94515b",
   "metadata": {},
   "source": [
    "Individual metrics are aggregated only across time-steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1629aa9-38ed-464f-a3a4-45245bd3c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_metrics.head() # i.e., time-steps is time axis and time series refers to individual predicted time-series (?) The total number of rows is 414;\n",
    "# len(item_metrics) 414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848da398-bb5c-482a-9d35-c31978235616",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_metrics.plot(x=\"MSIS\", y=\"MASE\", kind=\"scatter\")\n",
    "plt.grid(which=\"both\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f84b46-e09e-4ca3-956e-818de29c2c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (py_310)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
